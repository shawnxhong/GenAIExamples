# Path to all videos
videos: /video_ingest/videos/
# Path to video description generated by open-source vision models (ex. video-llama, video-llava, etc.)
description: /video_ingest/scene_description/
# Do you want to extract frames of videos (True if not done already, else False)
generate_frames: True
# Do you wnat to generate image embeddings?
embed_frames: True
# Path to store extracted frames
image_output_dir: /video_ingest/frames/
# Path to store metadata files
meta_output_dir: /video_ingest/frame_metadata/
# Number of frames to extract per second, 
# if 24 fps, and this value is 2, then it will extract 12th and 24th frame
number_of_frames_per_second: 2

vector_db:
  choice_of_db: 'chroma' # Supported databases [vdms, chroma]
  # choice_of_db: 'vdms' # Supported databases [vdms, chroma]
  host: <your IP>
  port: 9001
  # vectordb microservice urls
  vector_query_url: /visual_rag_retriever/query
  vector_init_url: /visual_rag_retriever/init_db
  vector_health_url: /health
  image_insert_url: /visual_rag_retriever/upload_images
  text_insert_url: /visual_rag_retriever/add_texts

# LLM path
model_path: ckpt/llama-2-7b-chat-hf
model_server:
  host: <your IP>
  port: 8866
  url: /generate