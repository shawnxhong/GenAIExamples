# Video RAG Distributed

## Introduction

This is a distributed version of VideoRAGQnA with 4 micoserverices:

1. vector store
2. LLM inference
3. streamlit UI
4. video ingest

each is separated as independent microservices.

Video RAG is a framework that retrives video based on provided user prompt. It uses both video scene description generated by open source vision models (ex video-llama, video-llava etc.) as text embeddings and frames as image embeddings to perform vector similarity search. The provided solution also supports feature to retrieve more similar videos without prompting it. (see the example video below)

![Example Video](docs/visual-rag-demo.gif)

## Tools

- **UI**: streamlit
- **Vector Storage**: Chroma DB **or** Intel's VDMS
- **Image Embeddings**: CLIP
- **Text Embeddings**: all-MiniLM-L12-v2
- **RAG Retriever**: Langchain Ensemble Retrieval
- **Model server**: Ray serve with Llama2-7b

## Prerequisites

There are 10 example videos present in ```video_ingest/videos``` along with their description generated by open-source vision model.
If you want these video RAG to work on your own videos, make sure it matches below format.

## File Structure

```bash
video_ingest/
.
├── scene_description
│   ├── op_10_0320241830.mp4.txt
│   ├── op_1_0320241830.mp4.txt
│   ├── op_19_0320241830.mp4.txt
│   ├── op_21_0320241830.mp4.txt
│   ├── op_24_0320241830.mp4.txt
│   ├── op_31_0320241830.mp4.txt
│   ├── op_47_0320241830.mp4.txt
│   ├── op_5_0320241915.mp4.txt
│   ├── op_DSCF2862_Rendered_001.mp4.txt
│   └── op_DSCF2864_Rendered_006.mp4.txt
└── videos
    ├── op_10_0320241830.mp4
    ├── op_1_0320241830.mp4
    ├── op_19_0320241830.mp4
    ├── op_21_0320241830.mp4
    ├── op_24_0320241830.mp4
    ├── op_31_0320241830.mp4
    ├── op_47_0320241830.mp4
    ├── op_5_0320241915.mp4
    ├── op_DSCF2862_Rendered_001.mp4
    └── op_DSCF2864_Rendered_006.mp4
```

## Setup and Installation

VideoRAGQnA supports both **docker compse setup** and **Helm chart** setup. For docker compose setup, please skip the `helm setup` steps. And for Helm usage, please skip the `docker compse setup` steps.

### Vector store microservice setup

Please build and run the service as the following steps:

```bash
cd VideoRAGQnADistributed/vectorDB_service
docker compose build
# docker compose setup:
docker compose up 
```

Currently ChromaDB and Intel's VDMS are supported.
For full API docs, please visit `http://server_ip:9001/docs` for automatic interactive API documentation

### Model server microservice setup

Please first setup your [huggingface hub API token](https://huggingface.co/login?next=%2Fsettings%2Ftokens).

And download the `llama-2-7b-chat-hf` model file as following:

```bash
export HUGGINGFACEHUB_API_TOKEN='<your HF token>'
cd VideoRAGQnADistributed
git clone https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
```

Please build and start the model server container as following:

```bash
cd VideoRAGQnADistributed/model_serve
docker compose build
# docker compose setup:
docker compose up
```

### video ingest & streamlit UI setup

The configs are listed in `VideoRAGQnADistributed/conf/config.yaml`. Please change the host IP of your vectorDB service & model server service in the yaml file.

```yaml
vector_db:
  choice_of_db: 'chroma' # Supported databases [vdms, chroma]
  host: <change the IP here>
model_path: ckpt/llama-2-7b-chat-hf
model_server:
  host: <change the IP here>
```

After the configs are done, please start the video ingest & streamlit UI as following:

```bash
cd VideoRAGQnADistributed/
docker compose build
# docker compose setup:
docker compose up
```

### Helm setup

Please skip this section if you have run *docker compose up*.

The configs are listed in `VideoRAGQnADistributed/helm/values.yaml`. Please update below fields.

```yaml
db_service:
  vectordb_host: "192.16.100.100" # IP of vectordb host
  choice_of_db: chroma # supported: chroma vdms

huggingface:
  api_token: "your-api-token"
  cache_dir: "/home/user/.cache/huggingface" # normally under ~/.cache/huggingface, please use absolute path.
```

Mount the model for rag_serve

```bash
cd VideoRAGQnADistributed/
cp -r ckpt /mnt/
```

Start the service

```bash
# start the service
helm install videorag helm/
# stop the service
helm uninstall videorag
```
